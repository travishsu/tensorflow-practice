{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from pandas import DataFrame, get_dummies\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, features, labels):\n",
    "        assert features.shape[0] == labels.shape[0], (\n",
    "        'features.shape: %s labels.shape: %s' % (features.shape,labels.shape))\n",
    "        self._num_examples = features.shape[0]\n",
    "\n",
    "        features = features.astype(np.float32)\n",
    "        self._features = features\n",
    "        self._labels = labels\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "    @property\n",
    "    def features(self):\n",
    "        return self._features\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "    def next_batch(self, batch_size):\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "          # Finished epoch\n",
    "          self._epochs_completed += 1\n",
    "          # Shuffle the data\n",
    "          perm = np.arange(self._num_examples)\n",
    "          np.random.shuffle(perm)\n",
    "          self._features = self._features[perm]\n",
    "          self._labels = self._labels[perm]\n",
    "          # Start next epoch\n",
    "          start = 0\n",
    "          self._index_in_epoch = batch_size\n",
    "          assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "        return self._features[start:end], self._labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FC_dim = 256\n",
    "PKL_DIR = './'\n",
    "\n",
    "epoch = 15\n",
    "\n",
    "def load():\n",
    "    with open(PKL_DIR + 'train.pkl', 'rb') as input:\n",
    "        train = pkl.load(input)\n",
    "        train_x = train['x'].astype('float32')\n",
    "        train_y = train['y']\n",
    "\n",
    "    with open(PKL_DIR + 'valid.pkl', 'rb') as input:\n",
    "        valid = pkl.load(input)\n",
    "        valid_x = valid['x'].astype('float32')\n",
    "        valid_y = valid['y']\n",
    "\n",
    "    with open(PKL_DIR + 'test.pkl', 'rb') as input:\n",
    "        test_x = pkl.load(input).astype('float32')\n",
    "\n",
    "    return train_x, train_y, valid_x, valid_y, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_weight_variables(shape, names):\n",
    "    w = tf.Variable(tf.truncated_normal(shape=shape), name=names[0])\n",
    "    b = tf.Variable(tf.truncated_normal(shape=[shape[1]]), name=names[0])\n",
    "    \n",
    "    return w, b\n",
    "    \n",
    "def activate(input_layer, weight, bias, activation=None):\n",
    "    linear_combination = tf.matmul(input_layer, weight) + bias\n",
    "    \n",
    "    if activation == None:\n",
    "        return linear_combination\n",
    "    elif activation == 'relu':\n",
    "        return tf.nn.relu(linear_combination)\n",
    "    elif activation == 'tanh':\n",
    "        return tf.nn.tanh(linear_combination)\n",
    "    elif activation == 'sigmoid':\n",
    "        return tf.nn.sigmoid(linear_combination)\n",
    "    elif activation == 'softmax':\n",
    "        return tf.nn.softmax(linear_combination)\n",
    "    \n",
    "def FullConnected_layer(input_layer, to_shape, names, activation=None):\n",
    "    origin_shape = input_layer.get_shape().as_list()[1]\n",
    "    W, b = create_weight_variables([origin_shape, to_shape], names)\n",
    "    output_layer = activate(input_layer, W, b, activation)\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_highway_weights(shape, name):\n",
    "    h_W, h_b = create_weight_variables([shape, shape], ['h_W_'+name, 'h_b_'+name])\n",
    "    t_W, t_b = create_weight_variables([shape, shape], ['t_W_'+name, 't_b_'+name])\n",
    "    c_W, c_b = create_weight_variables([shape, shape], ['c_W_'+name, 'c_b_'+name])\n",
    "    \n",
    "    return [h_W, h_b, t_W, t_b, c_W, c_b]\n",
    "\n",
    "def highway_activate(input_layer, weights, activations=['sigmoid', 'sigmoid', 'sigmoid']):\n",
    "    H = activate(input_layer, weights[0], weights[1], activations[0])\n",
    "    T = activate(input_layer, weights[2], weights[3], activations[1])\n",
    "    #C = activate(input_layer, weights[4], weights[5], activations[2])\n",
    "    C = 1 - T\n",
    "    \n",
    "    output_layer = tf.multiply(H, T) + tf.multiply(input_layer, C) \n",
    "    return output_layer\n",
    "\n",
    "def Highway_layer(input_layer, name, user_activations=['sigmoid', 'sigmoid', 'sigmoid']):\n",
    "    shape = input_layer.get_shape().as_list()[1]\n",
    "    output_layer = highway_activate(input_layer, create_highway_weights(shape, name), activations=user_activations)\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y, valid_x, valid_y, test_x = load()\n",
    "train_x = train_x.reshape(-1, 28*28)\n",
    "valid_x = valid_x.reshape(-1, 28*28)\n",
    "test_x = test_x.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 28*28))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "f = FullConnected_layer(x, 50, ['W_0', 'b_0'])\n",
    "\n",
    "# 1st layer\n",
    "highway_1    = Highway_layer(f,         'layer1')\n",
    "highway_2    = Highway_layer(highway_1, 'layer2')\n",
    "\n",
    "output_layer = FullConnected_layer(highway_2, 10, ['W_2', 'b_2'], activation='softmax')\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output_layer, y))\n",
    "#loss = tf.reduce_sum(output_layer)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1000 loss: 1.93161690235\n",
      "step: 2000 loss: 1.79904603958\n",
      "step: 3000 loss: 1.73361611366\n",
      "step: 4000 loss: 1.64230585098\n",
      "step: 5000 loss: 1.63058710098\n",
      "step: 6000 loss: 1.64889788628\n",
      "step: 7000 loss: 1.62399530411\n",
      "step: 8000 loss: 1.62130522728\n",
      "step: 9000 loss: 1.59957718849\n",
      "step: 10000 loss: 1.58775126934\n",
      "step: 11000 loss: 1.58957076073\n",
      "step: 12000 loss: 1.59713923931\n",
      "step: 13000 loss: 1.5932328701\n",
      "step: 14000 loss: 1.58517599106\n",
      "step: 15000 loss: 1.59274458885\n",
      "step: 16000 loss: 1.58883833885\n",
      "step: 17000 loss: 1.59347701073\n",
      "step: 18000 loss: 1.58712947369\n",
      "step: 19000 loss: 1.59396529198\n",
      "step: 20000 loss: 1.59030342102\n",
      "step: 21000 loss: 1.58493208885\n",
      "step: 22000 loss: 1.58883833885\n",
      "step: 23000 loss: 1.58664119244\n",
      "step: 24000 loss: 1.58468794823\n",
      "step: 25000 loss: 1.59054720402\n",
      "step: 26000 loss: 1.59079134464\n",
      "step: 27000 loss: 1.58688521385\n",
      "step: 28000 loss: 1.60397541523\n",
      "step: 29000 loss: 1.59689509869\n",
      "step: 30000 loss: 1.59347712994\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(train_x, get_dummies(train_y).values)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for _ in xrange(30000):\n",
    "        #r = np.random.randint(train_x.shape[0])\n",
    "        #fd = {x: [train_x[r]], y: [get_dummies(train_y).values[r]]}\n",
    "        x_batch, y_batch = dataset.next_batch(4096)\n",
    "        fd = {x: x_batch, y: y_batch}\n",
    "        sess.run(optimizer, feed_dict=fd)\n",
    "        if (_+1)%1000 == 0:\n",
    "            print(\"step: {} loss: {}\".format(_+1, sess.run(loss, feed_dict=fd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 784)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
